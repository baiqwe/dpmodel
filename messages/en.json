{
    "metadata": {
        "title": "DeepSeek Model1 Online: Free Test & API Playground (FlashMLA Supported)",
        "description": "Try DeepSeek Model1 (R1) instantly. No login required. Test FlashMLA performance, logic reasoning, and coding capabilities online. Free AI playground.",
        "keywords": "DeepSeek Model1, DeepSeek R1, FlashMLA, DeepSeek API, AI Playground, DeepSeek online, OpenAI o1 alternative, free AI chat"
    },
    "nav": {
        "home": "Home",
        "playground": "Playground",
        "comparison": "Comparison",
        "faq": "FAQ",
        "pricing": "Pricing",
        "about": "About",
        "sign_in": "Sign In",
        "sign_up": "Sign Up",
        "dashboard": "Dashboard",
        "sign_out": "Sign Out"
    },
    "hero": {
        "badge": "üöÄ FlashMLA Accelerated",
        "title": "DeepSeek Model1",
        "title_highlight": "Online Playground",
        "subtitle": "Benchmark DeepSeek Model1 (R1) with FlashMLA. Compare reasoning capabilities against OpenAI o1 instantly.",
        "cta_free": "üéØ Try Now - Free",
        "cta_signin": "üîí Full Access",
        "cta_start": "üöÄ Start Testing",
        "feature_1": "FlashMLA 3x Faster",
        "feature_2": "671B Parameters",
        "feature_3": "128K Context Window"
    },
    "playground": {
        "input_placeholder": "Enter your prompt to test DeepSeek Model1 / R1 performance...",
        "example_prompts": [
            "Explain the concept of FlashMLA and how it accelerates inference...",
            "Write a Python function to implement binary search with O(log n)...",
            "What are the key differences between transformer architectures...",
            "Solve this step by step: If a train travels 120km in 2 hours..."
        ],
        "run_button": "Run",
        "reset_button": "Reset",
        "generating": "Generating...",
        "response_title": "Model1 Response",
        "empty_state": "Enter a prompt above and click \"Run\" to test DeepSeek Model1...",
        "blur_message": "High traffic on Model1 nodes. Verify to continue.",
        "continue_button": "Continue with Full Access"
    },
    "stats": {
        "title": "Real-time Metrics",
        "status_ready": "Ready",
        "status_processing": "Processing",
        "version": "FlashMLA v2.1",
        "token_speed": "Token Speed",
        "latency": "Latency",
        "gpu_memory": "GPU Memory",
        "active_experts": "Active Experts",
        "context_used": "Context Used",
        "queue_position": "Queue Position",
        "model_info": "Model Info",
        "model_name": "deepseek-model1-r1",
        "parameters": "671B (37B active)",
        "architecture": "MoE + FlashMLA"
    },
    "comparison": {
        "title": "Model Comparison",
        "subtitle": "See how DeepSeek Model1 stacks up against other leading AI models",
        "feature": "Feature",
        "benchmark_note": "* Benchmarks based on publicly available data. Performance may vary.",
        "features": {
            "math_500": "MATH-500 Score",
            "humaneval": "HumanEval",
            "mmlu": "MMLU",
            "context_window": "Context Window",
            "open_source": "Open Source",
            "api_cost": "API Cost (per 1M tokens)",
            "flashmla": "FlashMLA Support",
            "reasoning": "Multi-step Reasoning"
        }
    },
    "faq": {
        "title": "Frequently Asked Questions",
        "subtitle": "Everything you need to know about DeepSeek Model1",
        "q1": "Is DeepSeek Model1 released?",
        "a1": "DeepSeek Model1 refers to DeepSeek's latest reasoning model lineup, including the R1 and V3 models. These are open-source and available via API.",
        "q2": "What is FlashMLA?",
        "a2": "FlashMLA (Flash Multi-head Latent Attention) is DeepSeek's optimized attention mechanism that provides up to 3x faster inference speed while reducing memory usage through latent compression.",
        "q3": "How does Model1 compare to OpenAI o1?",
        "a3": "DeepSeek Model1 achieves competitive or superior performance on benchmarks like MATH-500 (97.3% vs 96.4%) while being open-source and significantly cheaper ($0.14 vs $15 per 1M tokens).",
        "q4": "Is there an API available?",
        "a4": "Yes! DeepSeek provides official API access. You can also deploy Model1 on your own infrastructure using platforms like RunPod, Vultr, or AWS.",
        "q5": "What's the context window size?",
        "a5": "DeepSeek Model1 supports up to 128K tokens context window, allowing for long-form reasoning, document analysis, and extended conversations."
    },
    "features": {
        "title": "Why DeepSeek Model1?",
        "subtitle": "Next-generation AI reasoning with unprecedented efficiency.",
        "feature_1_title": "üß† Advanced Reasoning",
        "feature_1_desc": "Multi-step logical reasoning with chain-of-thought capabilities. Excels at math, coding, and complex problem-solving.",
        "feature_2_title": "‚ö° FlashMLA Speed",
        "feature_2_desc": "3x faster inference with optimized attention mechanism. Lower latency, higher throughput.",
        "feature_3_title": "üí∞ Extremely Affordable",
        "feature_3_desc": "$0.14 per 1M tokens. 100x cheaper than GPT-4, while matching or exceeding performance.",
        "feature_4_title": "üîì Open Source",
        "feature_4_desc": "Fully open weights and architecture. Deploy on your own infrastructure with complete control.",
        "feature_5_title": "üìä MoE Architecture",
        "feature_5_desc": "671B total parameters with only 37B activated per token. Efficient sparse computing.",
        "feature_6_title": "üåê 128K Context",
        "feature_6_desc": "Process entire codebases, long documents, and complex conversations in a single prompt."
    },
    "cta": {
        "title": "Ready to Experience Model1?",
        "subtitle": "Start testing DeepSeek's most powerful reasoning model. Free, instant, no login required.",
        "button_start": "Start Testing Now",
        "button_api": "Get API Access"
    },
    "footer": {
        "tagline": "Next-gen AI reasoning, open and accessible",
        "resources": "Resources",
        "legal": "Legal",
        "link_api": "API Documentation",
        "link_github": "GitHub",
        "link_huggingface": "HuggingFace",
        "link_privacy": "Privacy Policy",
        "link_terms": "Terms of Service",
        "link_about": "About",
        "rights": "All rights reserved."
    },
    "Pricing": {
        "title": "Unlock Full Potential",
        "subtitle": "Get priority access to DeepSeek Model1 with faster speeds and higher limits.",
        "monthly": "Monthly",
        "yearly": "Yearly",
        "start_pro": "Start Pro Plan",
        "get_pack": "Get Pack",
        "credits": "Credits",
        "generations": "API Calls",
        "price_per_image": "Price per Request",
        "secure_payment": "Secure payment via Stripe",
        "month": "mo",
        "year": "yr",
        "refill_title": "Out of Credits?",
        "refill_subtitle": "Top up instantly to continue using Model1.",
        "refill_upgrade": "Upgrade to Pro",
        "refill_mini": "Quick top-up $4.99",
        "restore_purchase": "Restore Purchases",
        "manage_subscription": "Manage Subscription",
        "error": "Error"
    },
    "common": {
        "loading": "Loading...",
        "error": "Error",
        "success": "Success",
        "cancel": "Cancel",
        "confirm": "Confirm",
        "close": "Close"
    }
}